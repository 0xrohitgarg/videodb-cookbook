{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "---\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/aws_rekognition/find_face_and_clip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "üë®‚Äçüç≥ This section of our cookbook demonstrates a method for using video analysis to identify and highlight significant moments involving people in a video\n",
    "\n",
    "ü•° Key components of this technique include::\n",
    "- **AWS Rekognition API**: The [FaceSearch](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartFaceSearch.html) endpoint of the AWS Rekognition API will be utilized to scan the video and detect the presence of individuals.\n",
    "- **VideoDB**: This tool will be used for storing the video in a database specifically designed for videos. It also aids in extracting and compiling clips of the identified person into a master clip.\n",
    "\n",
    "üå∂Ô∏è Most spicy thing about our dish ?   \n",
    "\n",
    "We will collect timestamps of persons presence, get clips from video, merge them all,  **without needing to touch video editor, waiting in render queue and instantly playable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Installing Required Packages\n",
    "\n",
    "To ensure our Python environment has the necessary tools, we need to install following packages:\n",
    "- boto3: to use aws services such as [S3](https://docs.aws.amazon.com/s3/) and [AWS rekognition api](https://docs.aws.amazon.com/rekognition/)\n",
    "- pytube: for downloading YouTube Videos.\n",
    "- videodb : to access videodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzi_JgKkTjNl",
    "outputId": "79308b64-d19b-439e-b680-be1151b7b600"
   },
   "outputs": [],
   "source": [
    "!pip install boto3 pytube requests videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "- `download_video_yt` : downloads a YouTube video at highest resolution, saving it with a specified filename.\n",
    "- `download_file` : downloads any file from a URL using wget, saving it with a specified name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g7Ke954-UFiA"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pytube\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "#Downloads Youtube video\n",
    "def download_video_yt(url, output_file=\"video.mp4\"):\n",
    "    youtube_object = pytube.YouTube(url)\n",
    "    video_stream = youtube_object.streams.get_highest_resolution()\n",
    "    video_stream.download(filename=output_file)\n",
    "    print(f\"Downloaded {url} as {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "#Downloads Image\n",
    "def download_file(url, output_file=\"image.jpg\"):\n",
    "    command = f\"wget -O {output_file} {url}\"\n",
    "    exit_status = os.system(command)\n",
    "    if exit_status == 0:\n",
    "        print(f\"Downloaded {url} as {output_file}\")\n",
    "    else:\n",
    "        print(\"An error occurred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading media\n",
    "Downloading and processing media. \n",
    "\n",
    "We will download a YouTube video and extract clips featuring a specific individual to create a new video focused on that person.   \n",
    "This demo will use a 15-minute Silicon Valley scene featuring Martin Starr(Gilfoyle), with a specific clip extracted for demonstration purposes\n",
    "\n",
    "But, you can change target media as per your needs using `video_url_yt_sv` and `target_person` \n",
    "\n",
    "\n",
    "<div style=\"background-color: #ffffcc; color: black; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Attention:</strong> We are using a paid API, so please select your YouTube video carefully. Choosing a larger video may incur additional charges.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "yA7onVlV5073",
    "outputId": "23a613e6-c8c5-4dfd-8685-90faf37f869a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded video to: video.mp4\n",
      "Downloaded image to: image.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'image.jpg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url_yt_sv = \"https://www.youtube.com/watch?v=NNAgJ5p4CIY\"\n",
    "image_gilfoyle = \"https://static.hbo.com/content/dam/hbodata/series/silicon-valley/characters/s3/gilfoyle-1920.jpg\"\n",
    "image_jinyang = \"https://static.hbo.com/content/dam/hbodata/series/silicon-valley/characters/s2/jian-yang-1920.jpg\"\n",
    "image_erlic = \"https://static.wikia.nocookie.net/silicon-valley/images/1/1f/Erlich_Bachman.jpg\"\n",
    "image_jared = \"https://static.hbo.com/content/dam/hbodata/series/silicon-valley/characters/s3/jared-s3-1920.jpg\"\n",
    "image_dinesh = \"https://static.wikia.nocookie.net/silicon-valley/images/e/e3/Dinesh_Chugtai.jpg\"\n",
    "image_richard = \"https://static.wikia.nocookie.net/silicon-valley/images/3/33/Richard_Hendricks.jpg\"\n",
    "\n",
    "indexed_faces = [{\n",
    "    \"img\": image_gilfoyle,\n",
    "    \"output\": \"image_gilfoyle.jpg\",\n",
    "    \"userid\": \"gilfoyle1\"\n",
    "},\n",
    "              {\n",
    "    \"img\": image_jinyang,\n",
    "    \"output\": \"image_jinyang.jpg\",\n",
    "    \"userid\": \"jinyang\"\n",
    "},\n",
    "              {\n",
    "    \"img\": image_erlic,\n",
    "    \"output\": \"image_erlic.jpg\",\n",
    "    \"userid\": \"erlic\"\n",
    "},\n",
    "                  {\n",
    "    \"img\": image_jared,\n",
    "    \"output\": \"image_jared.jpg\",\n",
    "    \"userid\": \"jared\"\n",
    "},\n",
    "                {\n",
    "    \"img\": image_dinesh,\n",
    "    \"output\": \"image_dinesh.jpg\",\n",
    "    \"userid\": \"dinesh\"\n",
    "},\n",
    "                {\n",
    "    \"img\": image_richard,\n",
    "    \"output\": \"image_richard.jpg\",\n",
    "    \"userid\": \"richard\"\n",
    "}\n",
    "               ]\n",
    "\n",
    "video_output = \"video.mp4\"\n",
    "image_output = \"image.jpg\"\n",
    "\n",
    "download_video_yt(video_url_yt_sv, video_output)\n",
    "\n",
    "for indexed_face in indexed_faces:\n",
    "  download_file(indexed_face['img'],indexed_face['output'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuartion\n",
    "We must set up AWS and the VideoDB api keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîó Setting Up a connection to db\n",
    "\n",
    "To connect to `VideoDB`, simply create a `Connection` object.\n",
    "\n",
    "This can be done by either providing your VideoDB API key directly to the constructor or by setting the `VIDEO_DB_API_KEY` environment variable with your API key.\n",
    "\n",
    "> üí° Your API key is available in the [VideoDB dashboard](https://console.videodb.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect, play_stream\n",
    "conn = connect(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è AWS Configuration\n",
    "\n",
    "- AWS secrets like `aws_secret_key_id`, `aws_secret_access_key` and `aws_reigon` \n",
    "- `collection_id` - This refers to the AWS collection in which we will store the indexed faces.  \n",
    "- `bucket_name` - This is the name of the S3 bucket where the video will be stored.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kVvXX51-IPD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "aws_access_key_id= \"YOUR_AWS_KEY_ID\"\n",
    "aws_secret_access_key = \"YOUR_AWS_SECRET_KEY\" \n",
    "region_name = \"YOUR_AWS_REIGON\"\n",
    "\n",
    "bucket_name = \"videorekog\"\n",
    "collection_id = \"videorekog\"\n",
    "\n",
    "\n",
    "rekognition_client = boto3.client(\n",
    "    \"rekognition\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name,\n",
    ")\n",
    "s3 = boto3.client('s3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition API Workflow\n",
    "\n",
    "- Create a collection for faces to store\n",
    "- Create a new user with given `user_id`\n",
    "- Index Face from image and store index in `collection_id`\n",
    "- Associate Index face with newly created user\n",
    "- Upload a video to S3 Bucket and Start face search using [StartFaceSearch](https://docs.aws.amazon.com/rekognition/latest/dg/search-face-with-image-procedure.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymoCXryBbHRC"
   },
   "outputs": [],
   "source": [
    "def index_faces_from_image(image_path, collection_id):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "\n",
    "    response = rekognition_client.index_faces(\n",
    "        CollectionId=collection_id,\n",
    "        DetectionAttributes=[\"ALL\"],\n",
    "        Image={\"Bytes\": image_bytes},\n",
    "    )\n",
    "\n",
    "    if not response[\"FaceRecords\"]:\n",
    "        print(f\"No faces detected in image: {image_path}\")\n",
    "    return response[\"FaceRecords\"][0][\"Face\"][\"FaceId\"]\n",
    "\n",
    "\n",
    "\n",
    "for indexed_face in indexed_faces:\n",
    "  rekognition_client.create_user(UserId=indexed_face[\"userid\"], CollectionId=collection_id)\n",
    "  face_id = index_faces_from_image(indexed_face[\"output\"], collection_id)\n",
    "  rekognition_client.associate_faces(CollectionId=collection_id, UserId=indexed_face[\"userid\"], FaceIds=[face_id])\n",
    "  indexed_face[\"faceid\"] = face_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEAGTx4bUDpn",
    "outputId": "cec95967-4322-4d1a-cc22-5418426c77e1"
   },
   "outputs": [],
   "source": [
    "# Start a Face Search Job \n",
    "def start_face_search(video_path, collection_id, bucket_name):\n",
    "    response = rekognition_client.start_face_search(\n",
    "        Video={\"S3Object\": {\"Bucket\": bucket_name, \"Name\": video_path}},\n",
    "        CollectionId=collection_id\n",
    "    )\n",
    "\n",
    "    return response[\"JobId\"]\n",
    "\n",
    "# Get Result of Face Search Job\n",
    "def get_face_search_results(job_id):\n",
    "    wait_for = 5\n",
    "    while True:\n",
    "        response = rekognition_client.get_face_search(JobId=job_id)\n",
    "        status = response[\"JobStatus\"]\n",
    "        if status == \"IN_PROGRESS\":\n",
    "            time.sleep(wait_for)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if status == \"SUCCEEDED\":\n",
    "        return response\n",
    "    else:\n",
    "        print(f\"Face search failed with status: {status}\")\n",
    "        return None\n",
    "\n",
    "# Upload our video to S3 Bucket\n",
    "s3.create_bucket(Bucket=bucket_name)\n",
    "s3.upload_file(video_output, bucket_name, video_output)\n",
    "\n",
    "# Search faces in uploaded video using Rekogntion API \n",
    "job_id = start_face_search(video_output, collection_id, bucket_name )\n",
    "print(job_id)\n",
    "face_res = get_face_search_results(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Shots from Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Clips Timestamps\n",
    "When the Rekognition API detects indexed faces from a collection, it provides timestamps. Our goal is to merge timestamps that are part of the same scene.  \n",
    "While the [AWS Segment API](https://docs.aws.amazon.com/rekognition/latest/dg/segment-api.html) is one way to do this, we'll use a simpler approach.\n",
    "If the interval between two timestamps is smaller than a specified `threshold`, they will be grouped as a single shot. \n",
    "Additionally, we will apply a `padding` on both the right and left sides of each shot for better context.\n",
    "\n",
    "You can experiment with both variables `threshold` and `padding` to get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjgB2DgVgZVO",
    "outputId": "e8fa4d68-5397-467d-f96b-180bc7abf03a"
   },
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "padding = 3\n",
    "\n",
    "for indexed_face in indexed_faces:\n",
    "   indexed_face[\"timestamps\"] = []\n",
    "\n",
    "for person in face_res[\"Persons\"]:\n",
    "    if \"FaceMatches\" in person and person[\"FaceMatches\"]:\n",
    "      for face in person[\"FaceMatches\"]:\n",
    "        face_id = face[\"Face\"][\"FaceId\"]\n",
    "        for indexed_face in indexed_faces:\n",
    "          if indexed_face[\"faceid\"] == face_id:\n",
    "            seconds = person[\"Timestamp\"]/1000\n",
    "            indexed_face[\"timestamps\"].append(seconds)\n",
    "\n",
    "\n",
    "def merge_timestamps(numbers, threshold, padding):\n",
    "    grouped_numbers = [[0, 0]]\n",
    "    current_group = [numbers[0]]\n",
    "\n",
    "    for i in range(1, len(numbers)):\n",
    "        if numbers[i] - numbers[i-1] <= threshold:\n",
    "            current_group.append(round(numbers[i]))\n",
    "        else:\n",
    "            left_end = current_group[0]-padding\n",
    "            right_end = current_group[-1]+padding\n",
    "            if(left_end <0):\n",
    "              left_end = 0\n",
    "            if(left_end < grouped_numbers[-1][-1]):\n",
    "              grouped_numbers[-1][-1] = right_end\n",
    "            else:\n",
    "              grouped_numbers.append([left_end, right_end])\n",
    "            current_group = [round(numbers[i])]\n",
    "\n",
    "    grouped_numbers.append([current_group[0] - padding, current_group[-1]+padding])\n",
    "    return grouped_numbers\n",
    "\n",
    "for indexed_face in indexed_faces:\n",
    "  indexed_face[\"shots\"] = merge_timestamps(indexed_face[\"timestamps\"], threshold, padding )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtYfoZXllz1s"
   },
   "source": [
    "\n",
    "### Extracting Clips from Video Using videodb\n",
    "\n",
    "The idea behind videodb is straightforward: it functions as a database specifically for videos. Similar to how you upload tables or JSON data to a standard database, you can upload your videos to videodb. You can also retrieve your videos through queries, much like accessing regular data from a database.\n",
    "\n",
    "Additionally, videodb enables you to swiftly create clips from your videos, ensuring a ‚ö°Ô∏è process, just like retreiving text data from a db.\n",
    "\n",
    "For this demo, we'll be uploading our Silicon Valley clip to `videodb`, which has been processed using the AWS Rekognition API, identified by the URL `video_url_yt_sv`. \n",
    "\n",
    "Following this, we will compile a master clip composed of smaller segments that depict the individual we have indexed using Rekognition API \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = conn.upload(url=video_url_yt_sv)\n",
    "for indexed_face in indexed_faces:\n",
    "  indexed_face[\"stream\"] = video.generate_stream(timeline=indexed_face[\"timeline\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "![Curtains](https://c.tenor.com/3-rQGspkeboAAAAd/tenor.gif)\n",
    "\n",
    "Now, its time to view our results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexed_face in indexed_faces:\n",
    "    if(indexed_face['userid']==\"erlic\"):\n",
    "        play_stream(indexed_face[\"stream\"])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
